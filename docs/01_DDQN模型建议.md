# DDQN模型建议文档

## 用于配对交易的10个DDQN模型架构

### 模型1: 基础DDQN (Baseline DDQN)
**架构特点:**
- 3层全连接网络 (128-64-32)
- ReLU激活函数
- 简单的经验回放缓冲区

**优点:**
- 实现简单，易于调试
- 训练速度快
- 适合初步验证

**缺点:**
- 可能无法捕捉复杂的市场模式
- 特征提取能力有限

**适用场景:** 作为基准模型，用于对比其他模型性能

---

### 模型2: 双流DDQN (Dueling DDQN)
**架构特点:**
- 分离价值流和优势流
- 共享特征提取层 (256-128)
- 价值流: 128-1
- 优势流: 128-动作数

**优点:**
- 更好地估计状态价值
- 在动作空间较大时表现优异
- 收敛更稳定

**缺点:**
- 网络复杂度稍高
- 需要更多计算资源

**适用场景:** 配对交易中有多个动作选择（买入/卖出/持有不同比例）

---

### 模型3: 注意力机制DDQN (Attention-based DDQN)
**架构特点:**
- 多头自注意力层处理时间序列特征
- 注意力权重可视化
- LSTM + 注意力 + 全连接

**优点:**
- 自动学习重要的时间步
- 捕捉长期依赖关系
- 可解释性强

**缺点:**
- 训练时间较长
- 参数量大

**适用场景:** 需要捕捉历史价格序列中的关键模式

---

### 模型4: 卷积DDQN (CNN-DDQN)
**架构特点:**
- 1D卷积层提取局部特征
- 多尺度卷积核 (3, 5, 7)
- 全局平均池化
- 全连接输出层

**优点:**
- 提取价格走势的局部模式
- 参数共享，减少过拟合
- 对平移不变性有优势

**缺点:**
- 需要合适的窗口大小
- 可能丢失全局信息

**适用场景:** 价格序列呈现明显的局部模式（如头肩顶、双底等）

---

### 模型5: LSTM-DDQN
**架构特点:**
- 双层LSTM (128-64)
- Dropout正则化
- 全连接输出层

**优点:**
- 擅长处理时间序列
- 记忆长期依赖
- 适合金融数据

**缺点:**
- 训练速度慢
- 容易梯度消失

**适用场景:** 配对交易中需要考虑长期价差均值回归趋势

---

### 模型6: 分层DDQN (Hierarchical DDQN)
**架构特点:**
- 高层策略选择交易方向
- 低层策略决定交易量
- 两层Q网络协同工作

**优点:**
- 分解复杂决策
- 可以学习不同时间尺度的策略
- 提高探索效率

**缺点:**
- 训练复杂度高
- 需要精心设计奖励函数

**适用场景:** 需要同时决策交易方向和仓位大小

---

### 模型7: 集成DDQN (Ensemble DDQN)
**架构特点:**
- 3-5个独立的DDQN网络
- 投票或平均机制融合预测
- Bootstrap采样训练

**优点:**
- 降低方差，提高稳定性
- 减少过拟合风险
- 鲁棒性强

**缺点:**
- 计算成本高
- 推理速度慢

**适用场景:** 追求高稳定性和低回撤的交易策略

---

### 模型8: Noisy DDQN
**架构特点:**
- 在网络权重中添加参数化噪声
- NoisyNet替代epsilon-greedy
- 自适应探索

**优点:**
- 探索更高效
- 不需要手动调节探索率
- 在高维状态空间表现好

**缺点:**
- 实现稍复杂
- 需要仔细调参

**适用场景:** 市场状态空间复杂，需要智能探索

---

### 模型9: 优先经验回放DDQN (Prioritized Experience Replay DDQN)
**架构特点:**
- 基于TD误差的优先级采样
- SumTree数据结构
- 重要性采样权重修正

**优点:**
- 更高效地利用经验
- 加快收敛速度
- 关注重要转移

**缺点:**
- 实现复杂
- 内存开销较大

**适用场景:** 训练数据有限，需要充分利用关键交易经验

---

### 模型10: Rainbow DQN (整合多种改进)
**架构特点:**
- 整合Dueling、Noisy、PER、Multi-step learning
- C51分布式强化学习
- N-step returns

**优点:**
- 集成最先进技术
- 性能最优
- 适应性强

**缺点:**
- 实现难度最高
- 调参复杂
- 计算资源需求大

**适用场景:** 追求最佳性能，有充足的计算资源和开发时间

---

## 推荐选择

### **首选: 模型2 - 双流DDQN (Dueling DDQN)**

**选择理由:**

1. **性能与复杂度平衡**: 相比Rainbow等复杂模型，Dueling DDQN在保持良好性能的同时实现相对简单

2. **理论优势**: 通过分离状态价值和动作优势，能更准确地评估每个动作的相对价值，这对配对交易中的买入/卖出/持有决策特别有用

3. **稳定性**: 在金融市场的非平稳环境中，Dueling架构提供了更稳定的学习过程

4. **可扩展性**: 架构清晰，易于后续添加其他改进（如优先经验回放）

5. **实践验证**: 在多个金融RL任务中表现优异

**实现优先级:**
- 第一阶段: 实现Dueling DDQN核心架构
- 第二阶段: 添加优先经验回放
- 第三阶段: 如时间允许，可考虑整合注意力机制

---

## 状态空间设计（适用于所有模型）

```python
状态特征:
1. 价差 (Spread): 当前价差、价差均值、价差标准差
2. 协整关系: 协整系数、半衰期
3. 技术指标: RSI, MACD, 布林带
4. 成交量特征: 相对成交量
5. 持仓信息: 当前仓位、未实现盈亏
6. 时间特征: 交易日时间、星期几
```

## 动作空间设计

```python
动作集合:
- 0: 平仓
- 1: 买入配对 (做多价差)
- 2: 卖出配对 (做空价差)
- 3: 持有当前仓位
```

## 奖励函数设计

```python
奖励 =
    α * (当期收益率) +
    β * (夏普比率改变) +
    γ * (最大回撤惩罚) +
    δ * (交易成本惩罚)
```

---

## 下一步: 实现Dueling DDQN

将在下一个文档中详细展示代码实现。
